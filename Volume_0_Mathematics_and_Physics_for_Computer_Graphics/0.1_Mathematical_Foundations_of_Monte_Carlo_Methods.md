- [蒙特卡洛方法的快速介绍](#蒙特卡洛方法的快速介绍)
- [随机变量与概率](#随机变量与概率)
- [概率分布：第1部分](#概率分布：第1部分)
- [概率性质](#概率性质)
- [统计概论](#统计概论)
- [期望值](#期望值)
- [方差与标准差](#方差与标准差)
- [概率分布：第2部分](#概率分布：第2部分)
- [抽样分布](#抽样分布)
- [概率分布函数和累积分布函数](#概率分布函数和累积分布函数)
- [随机变量函数的期望值：无意识统计学的规律](#随机变量函数的期望值：无意识统计学的规律)
- [逆变换抽样方法](#逆变换抽样方法)
- [估计](#估计)

# 蒙特卡洛方法的快速介绍

**蒙特卡罗方法的快速介绍**

> 蒙特卡罗是一类随机方法的统称。这类方法的特点是，可以在随机采样上计算得到近似结果，随着采样的增多，得到的结果是正确结果的概率逐渐加大，但在(放弃随机采样，而采用类似全采样这样的确定性方法)获得真正的结果之前，无法知道目前得到的结果是不是真正的结果。

人的身高可以被看成是一个随机变量，通常使用大写字母 $$X$$ 来表示 **随机变量** 。

在统计数据中，**构成随机变量集的元素**，用小写字母 $$x$$ 来表示。

那么我们就可以从 $$n$$ 个样本中逼近人口的平均身高：

$$Approximation(Average(X)) = { 1 \over N} \sum_{n=1}^N x_n.$$

使用 $$M$$ 来表示整个人口的大小，那么准确的人口平均身高的期望值 $$E(X)$$ 为：
$$E(X) = Average(X) = { 1 \over M\ } (x_1 + x_2 + ... x_M)$$

> **蒙特卡洛近似** 是一种使用样本近似随机变量来得到期望的技术。可以使用下面公式在数学上定义：
> $$E(X) \approx { 1 \over N } \sum_{n = 1}^N x_n.$$

---

**蒙特卡洛，偏向和无偏光线追踪**

在数码相机拍照中，如果将图像的表面划分为规则的网格，那么每一个像素都对应着场景中的一个区域。这个区域中的多个对象被转换为单一的像素颜色。


![mark](http://o9z9uibed.bkt.clouddn.com/image/20171107/205406386.png?imageslim)

理想的情况下，为了得到这个元素的颜色，我们要做的是计算通过这个像素的总光量。我们可以用以下的数学公式来表达这个观点:

$$L_{pixel} = \int_{pixel area} L(x_p) dA$$

但是没有一个方法可以实际上在像素对应着的场景表面进行积分，这个积分实际上没有解决方法。

---


但是我们可以使用“随机采样”来近似这个积分：

![mark](http://o9z9uibed.bkt.clouddn.com/image/20171107/210324932.png?imageslim)

我们需要的是在像素区域中选择一些随机采样位置并平均其颜色。

$$L_{pixel} \approx {1 \over N } \sum_{n=1}^N L(x_n)$$

---

我们计算 $$E(X)$$ 的近似值的规则称为估计量。等式：

$$Approximation(E(X)) = { 1 \over N } \sum_{n=1}^N x_n,$$


如果 **估计量** 随着 **样本量N** 的增加而越接近 **期望值** ，则估计量就是无偏的。

$$ Approximation(E(X)) - E(X) = 0 \text { as N approaches } \infty. $$

蒙特卡洛估计是一个无偏估计量。

---

> 蒙特卡洛方法是依靠随机抽样来近似结果的数值技术，特别是近似积分的结果。
>
> 蒙特卡洛绝对是渲染领域的核心。它与许多非常重要的其他主题相关，如采样，重要性采样，光传输算法等，并且还用于其他许多重要的渲染技术(尤其是阴影处理)。

---


# 随机变量与概率
可以使用数学符号表示**硬币正面或者反面**的概率：
$$
X(\omega) =
\begin{cases}
1, & \text{if} \ \ \omega = \text{heads} , \\
 \\
 0, & \text{if} \ \ \omega = \text{tails} .
\end{cases}
$$

$X$ 就是**随机变量**，是一个关于$$\omega$$的函数，$$\omega$$是**随机过程**的结果。

也就是说，随机变量不是一个固定的值，而是一个函数，将随机过程的可能结果(硬币的正面或者反面)映射到数字0或者1。

**随机过程** 的定义是产生不可预测的结果，然而 **概率** 可以用来描述随机过程中发生特定事件的机会。

---

**术语**：

- 大写字母 $$X,Y,Z...$$ 来表示**随机变量函数**
- 小写字母 $$x,y,z...$$ 表示**观测结果**
- 使用$$S = \{1, 2, 3, 4, 5, 6\}$$ 表示**样本空间**
- 使用 $$x_1,x_2,...,x_n$$ 表示**事件**
- **事件** 是 **样本空间** 的子集

---

# 概率分布：第1部分
离散的随机变量分布使用散点来表示，连续的随机变量分布使用曲线来表示。

**二项分布**

当一个随机过程只有两个结果(比如“头”或“尾”，“成功”或“失败”)时，我们会谈论伯努利(或二项式)试验。

比如：抛硬币6次，那么得到4个头的概率是多少？

$$Pr(S = n) = C_n^N p^k(1-p)^{(N-n)}$$

---

**正态分布**

正态分布与二项分布非常相似，但二项分布适用于 **离散随机变量** ，正态分布适用于 **连续随机变量**。

---

# 概率性质

**相互排斥和集体穷举的事件**

样本空间的定理和属性与集合类似。

比如当样本空间$$A=\{1,2,3\}$$，样本空间$$B=\{3,4,5\}$$，A和B是两个不相交的集合，那么**样本空间**对应的**事件**就是不能同时发生的，或者说是**互斥**的。

---

**互斥事件和相互独立事件**

互斥事件一起发生的概率： $$Pr(A \cap B) = 0$$

独立事件一起发生的概率： $$Pr(A \cap B) = Pr(A)Pr(B)$$


---

**概率性质**

事件`A`(A为样本空间可能的结果之一)发生的概率为$$Pr(A)$$，$$Pr(A)$$需要实际满足三个公理：
- 对于每个事件A，$$Pr(A) \ge 0$$
- 如果一个事件肯定会发生，那么该事件的概率是1。
- 任何互相排斥的$$E1,E2,...$$ 事件的发生的概率(E1发生 **或者** E2发生 **或者** ...)满足：$$Pr(E_1 \cup E_2 \cup \;...) = \sum_{i=1}^\infty Pr(E_i).$$

---

# 统计概论

我们不知道10张牌中有多少张牌的数字是0,1或2。总之，我们不知道这个实验产生的随机变量，除了返回数字在0到2之间，我们对这些数字的概率分布一无所知，因此我们不能用 **概率计算** 来估计获得0或2的概率。但我们可以猜测吗？答案是肯定的，这正是 **统计** 的目标。


统计的目标是提供关于 **随机变量** 和 **概率分布** 的信息，这些信息我们一开始是不知道的。

---

# 期望值

**平均值或者算术平均值** 是一个简单的概念，只需要对数据进行累加，然后除于数据的个数即可。

$$\mu =  \dfrac{1}{N} (v_1 + v_2 + ... + v_N).$$

---

一个结果和概率已知的实验的 **期望值** 可以通过将 **样本空间的值** 乘以它们个体的 **概率** 累加起来计算得出。

> **平均值** 和 **期望值** 是相等的，然而 **平均值** 是没有任何加权的数字的简单平均值，而 **期望值** 是通过它们各自概率加权的数字的总和。

$$EV = \sum_{i=1}^N p_i x_i.$$

---

在卡片的例子中，其平均值和期望值各自如下：

$$\begin{array}{l}
\mu &=&\dfrac{(0+0+1+1+1+1+1+2+2+2)}{10}=1.1, \\
EV&=&0 * 0.2 + 1 * 0.5 + 2 * 0.3=1.1.
\end{array}$$

---

**样本均值**

在大多数的情况下，实验的概率分布和结果是不知道的，此时需要利用 **随机采样** 对概率的分布进行估计。随机变量 $$X$$ 产生的观测值的集合被称为 **样本均值** $$\bar X$$ 。

$$\bar X_n = \dfrac{1}{n} (X_1 + X_2 + ... + X_n)  \  = {1 \over n } (x_1+x_2+...+x_n)  \ = {1 \over n} (X_1(\omega)+X_2(\omega) + ... + X_n(\omega).$$

> 大写字母$$X_1 X_2$$ 是一系列随机变量，它们的性质是独立分布的。

> 随机变量$$X$$实例上是从 **样本空间S** 到 **实数空间R** 的一个函数。

> 小写字母$$x_1 x_2$$ 是一些列观察值，即$$x = X(\omega)$$。

---

随着样本规模的增加，**样本均值** 收敛于 **期望值** ：

$$\bar X_n \approx EV.$$

随着我们不断增加试验次数，**随机变量的样本均值** $$\bar X_n$$ 趋近于一个极限，这个极限是 **随机变量的期望值**$$E(X)$$。

随机变量的期望值 $$E(X)$$ 和总体均值 $$\mu$$ 是相等的。


$$\bar X_n \rightarrow E[X] = \mu \text{ as } n \rightarrow \infty.$$

---

概率收敛：

$$\begin{array}{l} \lim_{n \rightarrow \infty} \text{ Pr }(|\bar X_n - \mu| < \epsilon) = 1.\end{array}$$

> 随机变量的 **样本均值** $$\bar X_n$$ `概率收敛`于随机样本所在群体的 **总体平均值**  $$\mu$$ .

---

# 方差与标准差

**标准差** 是 **方差Variance** 的平方根，方差可以表示为：
$$Var(X) = \sigma^2 = E[(X - E[X])^2] = \sum_i (x_i - E[X])^2p_i.$$

方差的表示式可以扩展为：

$$\begin{array}{l}
E[(X - E[X])^2] & = & E[(X - \mu)^2]   \\  
& = & E[X^2 + \mu^2 - 2 X\mu]   \\  
& = & E[X^2] -2E[X]\mu + E[\mu^2]   \\  
& = & E[X^2] - 2\mu^2 + \mu^2   \\  
& = & E[X^2] - \mu^2   \\  
& = & \sum_i x_i^2 p_i - (\sum_i x_i p_i)^2   \\  
& = & \sum_i x_i^2 p_i - \mu^2.
\end{array}$$

---

如果所有的随机变量具有相同的概率：


$$Var(X) = \sum_{i=1}^n{ { (x_i - \bar X)^2} \over n }.$$

---

**方差的属性** 可以通过 **期望的四个公式** 以及 **一个方差公式** 推出：

$$\begin{array}{l}
E[X + c] = E[X] + c,   \\   E[cX] = c E[X],   \\   E[X +Y] = E[X]+E[Y],  \\  E[E[X] = E[X].
\end{array}$$

$$
\begin{array}{l}
Var(X) &=& E[(X - E[X])^2]   \\   & =& E[X^2 - 2X E[X] + E[X]^2],  \\  
& =& E[X^2] - 2 E[X] E[X] + E[X]^2,   \\  
& =& E[X^2] - E[X]^2.
\end{array}
$$

---

# 概率分布：第2部分

**正态分布(Gaussian or Normal distribution)** 高斯分布或者正态分布具有典型的钟型曲线，这个分布的公式如下：
$$p(x) = \mathcal{N}(\mu, \sigma) = {\dfrac{1}{\sigma \sqrt {2 \pi} } } e^{-{\dfrac{(x -\mu)^2}{2\sigma^2}}}.$$

- 分布的标准偏差: $$\sigma$$
- 分布的期望：$$\mu$$
- $$\mathcal{N}(0,1)$$被称为标准分布


![mark](http://o9z9uibed.bkt.clouddn.com/image/20180123/093836725.png?imageslim)

---

# 抽样分布


**抽样分布：统计量分布、随机变量函数分布**

抽样分布也称统计量分布、随机变量函数分布，是指样本估计量的分布。**样本估计量** 是样本的一个函数，在统计学中称作 **统计量** ，因此抽样分布也是指统计量的分布。

> 根据 **样本** 的不同， **样本的估计量** 也不同，所以说样本估计量是样本的一个函数。

> 比如为了研究6000个人的平均分数，从中随机抽取500个人组成样本进行观察。每一次都会得到不完全相同的 **样本均值** ，全部可能的 **样本均值** 组成了一个对应的概率分布，就是 **样本均值的抽样分布** 。

---

**样本均值抽样分布的特征**

$$\begin{array}{l}
\mu_{\bar X} = \mu \\
\sigma_{\bar X} = \dfrac{\sigma}{\sqrt{n}}.
\end{array}$$

**数学期望**
样本均值的数学期望与总体期望一样：
$$\mu_{x} = \mu$$
![mark](http://o9z9uibed.bkt.clouddn.com/image/20180123/111000144.png?imageslim)

**方差**

样本均值的方差为总体方差的1/n，即：
$$\sigma_{x}^{2} = \sigma^{2} / n$$

![mark](http://o9z9uibed.bkt.clouddn.com/image/20180123/105844306.png?imageslim)

---

在人口身高的统计中：
- 总体均值$$\mu$$是用于定义数量的平均值的 **总体参数** 。参数是固定的。
- 使用样本来估计一个总体参数的时候，样本的估计量是一个 **统计量**，也是一个随机变量。
- 统计的值可能会因为 **样本** 而异。

| 属性                   | 人口(参数)                                                                                 | 样本(统计)                                                                                   |
| ---------------------- | -------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------- |
| $$\bar x \approx \mu$$ |     $$\mu$$                                                                              | $$\bar x$$                                                                                         |
| Mean 均值                  | $$\mu = \dfrac{\sum_{i=1}^N {x_i}}{N}$$                                                      | $$\bar X = \dfrac{\sum_{i=1}^n x_i }{n}$$                                                      |
| Variance 方差              | $$\sigma^2 = \dfrac{\sum_{i=1}^N {(x_i - \mu)^2}}{N} = \dfrac{\sum_{i=1}^N x_i}{N} - \mu^2$$ | $$S_n^2 = \dfrac{\sum_{i=1}^n (x_i - \bar X)^2 }{n} = \dfrac{\sum_{i=1}^n x_i}{n} - \bar X^2$$ |
|        N or n                |        N是全部的人口                                                                                      | n是样本的大小(比如抛掷硬币的次数)                                                                                               |

---

> 根据大数定律，当n接近无穷大时，样本平均值 **概率收敛** 于期望值$$\mu$$。
$$\begin{array}{l}
\lim_{n \rightarrow \infty} \text{ Pr }(|\bar X - \mu| < \epsilon) = 1 \\
\bar X \rightarrow \mu.
\end{array}$$

---

> 一个统计量的抽样分布是该统计量的分布，当从大小为n的随机样本中导出时，是一个随机变量，。换句话说，均值的抽样分布是样本均值的分布。

---

> 就像人口可以用平均数等参数来描述一样，抽样分布也是如此。换句话说，我们可以应用样本或统计方法来计算均值，而不是我们用来计算随机变量平均值的方法。当应用于样本时，结果值被称为均匀分布的期望值，可以定义为：
$$\mu_{\bar X} = E(\bar X) = \sum_{i=1}^n p_i \bar X_i,$$

> 其中 $$pi$$ 是与样本均值 $$Xi$$ 相关的概率，而这些概率本身是根据抽样分布分布的。当以相同的概率(即均匀分布)绘制样本时，概率仅为$$1/n$$，其中n代表样本或统计的数量(而不是样本大小)。

---

## **样本均值的性质**

---

样本均值：
$$\bar X = \dfrac{1}{n} (X_1 + ... + X_n)$$

样本均值的期望值等于总体均值：
$$E[\bar X_n] = \dfrac{1}{n} \sum_{i=1}^n E[X_i] = \dfrac{1}{n} \cdot { n \mu } = \mu.$$

是分为三步证明的：

1.期望值的两个属性：
$$\begin{array}{l}
E[aX+b] = aE[X] + b\\E[X_1 + ... + X_n] = E[X_1] + ... + E[X_n].
\end{array}$$

2.所以样本均值的期望为：
$$\begin{array}{l}
E[\bar X]&=&E[\dfrac{1}{n}(X_1 + ... + X_n)]\\
&=&\dfrac{1}{n}E[X_1 + ... + X_n]\\
&=&\dfrac{1}{n} \sum_{i=1}^N E[X_i].
\end{array}$$

3.而随机变量的期望值为$$\mu$$，所以可以使用$$\mu$$来代替$$E[X_i]$$，所以上式为：
$$E[\bar X] = \mu$$


---

样本均值的方差等于总体方差/n：
$$\begin{array}{l}
Var(\bar X_n)&=&\dfrac{1}{n^2} Var \left( \sum_{i=1}^n X_i \right) \\
&=&\dfrac{1}{n^2 } \sum_{i=1}^n Var(X_i) = \dfrac{1}{n^2} \cdot n \sigma^2 = \dfrac{\sigma^2}{n}.
\end{array}$$

分为以下几步证明：

1.方差的属性：
$$\begin{array}{l}
Var(aX + b) = a^2Var(X)\\Var(X_1+...+X_n) = Var(X_1) + ... + Var(X_n).
\end{array}$$

2.继续：
$$\begin{array}{l}
Var(\bar X)&=&Var(\dfrac{1}{n}(X_1 + ... X_n))\\
&=&\dfrac{1}{n^2 } Var(X_1 + ... X_n)\\
&=&\dfrac{1}{n^2 } \sum_{i=1}^n Var(X_i).
\end{array}$$

3.$$Var(X) = \sigma^{2}$$，，所以上式为：
$$Var(\bar X) = \dfrac{\sigma^2}{n }$$

---

# 概率分布函数和累积分布函数

**概率分布函数**

概率分布为随机试验的每一个可能的结果(**即随机变量**)分配一个概率。随机变量可以是离散的或者是连续的(比如投掷骰子得到的个数就是离散随机变量，而伦敦的下雨量就是连续随机变量)。

- 当一个函数定义了一个 **离散概率分布** 时，我们把这个函数称为 **概率质量函数PMF**，**概率质量函数** 是离散随机变量的概率分布，。
- 当一个函数定义了一个 **连续概率分布** 时，我们把这个函数称为 **概率密度函数PDF**，**概率密度函数** 是连续随机变量的概率分布。


**概率分布函数** 可以用来计算一个随机变量位于一个区间内的概率：

$$Pr( a \le X \le b) = \int_a^b pdf(x)\:dx.$$

---

**累积分布函数CDF**

概率分布函数最重要的属性之一是概率之和必须等于1，如果概率分布函数为$$g(x)$$，那么：

$$\int_{-\infty}^{\infty} g(x) dx = 1.$$

# 随机变量函数的期望值：无意识统计学的规律

一个**离散的随机变量X的期望值**是每个结果乘于其概率的总和：

$$E[X] = \sum_{i=0}^{N-1} X_i \ pmf(X_i)$$

如果我们将这个概念延伸到一个连续的随机变量，我们得到：
$$E[X] = \int_{-\infty}^{\infty} X pdf(X).$$

---

记$$F(X)$$为随机变量$$X$$的函数，那么：
- 如果X是一个随机变量，则X，F(X)的任何函数也是随机的。
- $$X$$ 和 $$F(X)$$ 有唯一的概率分布(除非 `F(X)= X` )。


对于离散随机变量X，其函数`F(X)`的期望为：
$$E[F(X)] = E[Y] = \sum Y_i P_Y(Y_i)  = \sum F(X_i) P_X(X_i).$$

对于连续随机变量X，其函数`F(X)`的期望为：
$$E[F(X)] = \int F(X) P_X(X) \:dX$$

---

# 逆变换抽样方法

仅仅想使用一个均匀概率分布函数`drand48()`来得到一个正态分布：

我们实际上可以通过简单地绘制在0和1之间均匀分布的随机数来绘制随机数和随机数的概率值`(x,PDF(x))`来做出一个正态分布。

这实质上是 **逆变换抽样法** 的原理。

$$InvCDF(drand48()) = y$$

我们的目标是用给定的概率密度函数或PDF来模拟随机过程。


---


# 估计

**估计和估计量**

估计量的概念是样本均值的一种推广，称为$$\theta$$。

可观测数据`x_1, ... x_n`集合的函数被称为$$\delta(x_1, ... x_n)$$。也是 $$\theta$$ 的估计量。


一个估计量 $$\delta(x_1,...,x_n)$$ 就是通过使用可观测值`x1,...,xn`来确定的。估计量是随机向量X的函数$$\delta(X)$$，同样，估计量恰好是这样一个特定值$$\delta(x)$$。


---

**无偏和有偏估计**

- 无偏估计

之前我们证明了当样本规模接近无穷大时，样本均值以概率收敛于总体均值：
$$\bar X_n \rightarrow \theta \quad \text{ for } n \rightarrow \infty.$$

用样本均值的期望值来表示这种关系：
$$E[\bar X_n] - \theta = 0.$$

- 有偏估计
$$E[\delta_{biases}(X)] - \theta = \text{ bias }.$$
