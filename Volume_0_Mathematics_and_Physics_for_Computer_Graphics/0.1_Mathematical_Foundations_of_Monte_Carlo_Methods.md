- [蒙特卡洛方法的快速介绍](#蒙特卡洛方法的快速介绍)
- [随机变量与概率](#随机变量与概率)
- [概率分布：第1部分](#概率分布：第1部分)
- [概率性质](#概率性质)
- [统计概论](#统计概论)
- [期望值](#期望值)
- [方差与标准差](#方差与标准差)
- [概率分布：第2部分](#概率分布：第2部分)
- [抽样分布](#抽样分布)
- [概率密度函数和累积分布函数](#概率密度函数和累积分布函数)
- [随机变量函数的期望值](#随机变量函数的期望值)
- [无意识统计](#无意识统计)
- [逆变换抽样方法](#逆变换抽样方法)
- [估计](#估计)

# 蒙特卡洛方法的快速介绍

**蒙特卡罗方法的快速介绍**

> 蒙特卡罗是一类随机方法的统称。这类方法的特点是，可以在随机采样上计算得到近似结果，随着采样的增多，得到的结果是正确结果的概率逐渐加大，但在（放弃随机采样，而采用类似全采样这样的确定性方法）获得真正的结果之前，无法知道目前得到的结果是不是真正的结果。

人的身高可以被看成是一个随机变量，通常使用大写字母 $$X$$ 来表示 **随机变量** 。

在统计数据中，**构成随机变量集的元素**，用小写字母 $$x$$ 来表示。

那么我们就可以从 $$n$$ 个样本中逼近人口的平均身高：

$$Approximation(Average(X)) = { 1 \over N} \sum_{n=1}^N x_n.$$

使用 $$M$$ 来表示整个人口的大小，那么准确的人口平均身高的期望值 $$E(X)$$ 为：
$$E(X) = Average(X) = { 1 \over M\ } (x_1 + x_2 + ... x_M)$$

> **蒙特卡洛近似** 是一种使用样本近似随机变量来得到期望的技术。可以使用下面公式在数学上定义：
> $$E(X) \approx { 1 \over N } \sum_{n = 1}^N x_n.$$

---

**蒙特卡洛，偏向和无偏光线追踪**

在数码相机拍照中，如果将图像的表面划分为规则的网格，那么每一个像素都对应着场景中的一个区域。这个区域中的多个对象被转换为单一的像素颜色。


![mark](http://o9z9uibed.bkt.clouddn.com/image/20171107/205406386.png?imageslim)

理想的情况下，为了得到这个元素的颜色，我们要做的是计算通过这个像素的总光量。我们可以用以下的数学公式来表达这个观点:

$$L_{pixel} = \int_{pixel area} L(x_p) dA$$

但是没有一个方法可以实际上在像素对应着的场景表面进行积分，这个积分实际上没有解决方法。

---


但是我们可以使用“随机采样”来近似这个积分：

![mark](http://o9z9uibed.bkt.clouddn.com/image/20171107/210324932.png?imageslim)

我们需要的是在像素区域中选择一些随机采样位置并平均其颜色。

$$L_{pixel} \approx {1 \over N } \sum_{n=1}^N L(x_n)$$

---

我们计算 $$E(X)$$ 的近似值的规则称为估计量。等式：

$$Approximation(E(X)) = { 1 \over N } \sum_{n=1}^N x_n,$$


如果 **估计量** 随着 **样本量N** 的增加而越接近 **期望值** ，则估计量就是无偏的。

$$ Approximation(E(X)) - E(X) = 0 \text { as N approaches } \infty. $$

蒙特卡洛估计是一个无偏估计量。
---

> 蒙特卡洛方法是依靠随机抽样来近似结果的数值技术，特别是近似积分的结果。
>
> 蒙特卡洛绝对是渲染领域的核心。它与许多非常重要的其他主题相关，如采样，重要性采样，光传输算法等，并且还用于其他许多重要的渲染技术（尤其是阴影处理）。

---


# 随机变量与概率
可以使用数学符号表示**硬币正面或者反面**的概率：
$$
X(\omega) =
\begin{cases}
1, & \text{if} \ \ \omega = \text{heads} , \\
 \\
 0, & \text{if} \ \ \omega = \text{tails} .
\end{cases}
$$

$X$ 就是**随机变量**，是一个关于$$\omega$$的函数，$$\omega$$是**随机过程**的结果。

也就是说，随机变量不是一个固定的值，而是一个函数，将随机过程的可能结果（硬币的正面或者反面）映射到数字0或者1。

**随机过程** 的定义是产生不可预测的结果，然而 **概率** 可以用来描述随机过程中发生特定事件的机会。

---

**术语**：

- 大写字母 $$X,Y,Z...$$ 来表示**随机变量函数**
- 小写字母 $$x,y,z...$$ 表示**观测结果**
- 使用$$S = \{1, 2, 3, 4, 5, 6\}$$ 表示**样本空间**
- 使用 $$x_1,x_2,...,x_n$$ 表示**事件**
- **事件** 是 **样本空间** 的子集

---

# 概率分布：第1部分
离散的随机变量分布使用散点来表示，连续的随机变量分布使用曲线来表示。

**二项分布**

当一个随机过程只有两个结果（比如“头”或“尾”，“成功”或“失败”）时，我们会谈论伯努利（或二项式）试验。

比如：抛硬币6次，那么得到4个头的概率是多少？

$$Pr(S = n) = C_n^N p^k(1-p)^{(N-n)}$$

---

**正态分布**

正态分布与二项分布非常相似，但二项分布适用于 **离散随机变量** ，正态分布适用于 **连续随机变量**。

---

# 概率性质

**相互排斥和集体穷举的事件**

样本空间的定理和属性与集合类似。

比如当样本空间$$A=\{1,2,3\}$$，样本空间$$B=\{3,4,5\}$$，A和B是两个不相交的集合，那么**样本空间**对应的**事件**就是不能同时发生的，或者说是**互斥**的。

---

**互斥事件和相互独立事件**

互斥事件一起发生的概率： $$Pr(A \cap B) = 0$$

独立事件一起发生的概率： $$Pr(A \cap B) = Pr(A)Pr(B)$$


---

**概率性质**

事件`A`(A为样本空间可能的结果之一)发生的概率为$$Pr(A)$$，$$Pr(A)$$需要实际满足三个公理：
- 对于每个事件A，$$Pr(A) \ge 0$$
- 如果一个事件肯定会发生，那么该事件的概率是1。
- 任何互相排斥的$$E1,E2,...$$ 事件的发生的概率(E1发生 **或者** E2发生 **或者** ...)满足：$$Pr(E_1 \cup E_2 \cup \;...) = \sum_{i=1}^\infty Pr(E_i).$$

---

# 统计概论

我们不知道10张牌中有多少张牌的数字是0,1或2。总之，我们不知道这个实验产生的随机变量，除了返回数字在0到2之间，我们对这些数字的概率分布一无所知，因此我们不能用 **概率计算** 来估计获得0或2的概率。但我们可以猜测吗？答案是肯定的，这正是 **统计** 的目标。


统计的目标是提供关于 **随机变量** 和 **概率分布** 的信息，这些信息我们一开始是不知道的。

---

# 期望值

**平均值或者算术平均值** 是一个简单的概念，只需要对数据进行累加，然后除于数据的个数即可。

$$\mu =  \dfrac{1}{N} (v_1 + v_2 + ... + v_N).$$

---

一个结果和概率已知的实验的 **期望值** 可以通过将 **样本空间的值** 乘以它们个体的 **概率** 累加起来计算得出。

> **平均值** 和 **期望值** 是相等的，然而 **平均值** 是没有任何加权的数字的简单平均值，而 **期望值** 是通过它们各自概率加权的数字的总和。

$$EV = \sum_{i=1}^N p_i x_i.$$

---

在卡片的例子中，其平均值和期望值各自如下：

$$\begin{array}{l}
\mu &=&\dfrac{(0+0+1+1+1+1+1+2+2+2)}{10}=1.1, \\
EV&=&0 * 0.2 + 1 * 0.5 + 2 * 0.3=1.1.
\end{array}$$

---

**样本均值**

在大多数的情况下，实验的概率分布和结果是不知道的，此时需要利用 **随机采样** 对概率的分布进行估计。随机变量 $$X$$ 产生的观测值的集合被称为 **样本均值** $$\bar X$$ 。

$$\bar X_n = \dfrac{1}{n} (X_1 + X_2 + ... + X_n)  \  = {1 \over n } (x_1+x_2+...+x_n)  \ = {1 \over n} (X_1(\omega)+X_2(\omega) + ... + X_n(\omega).$$

> 大写字母$$X_1 X_2$$ 是一系列随机变量，它们的性质是独立分布的。

> 随机变量$$X$$实例上是从 **样本空间S** 到 **实数空间R** 的一个函数。

> 小写字母$$x_1 x_2$$ 是一些列观察值，即$$x = X(\omega)$$。

---

随着样本规模的增加，**样本均值** 收敛于 **期望值** ：

$$\bar X_n \approx EV.$$

随着我们不断增加试验次数，**随机变量的样本均值** $$\bar X_n$$ 趋近于一个极限，这个极限是 **随机变量的期望值**$$E(X)$$。

随机变量的期望值 $$E(X)$$ 和总体均值 $$\mu$$ 是相等的。


$$\bar X_n \rightarrow E[X] = \mu \text{ as } n \rightarrow \infty.$$

---

概率收敛：

$$\begin{array}{l} \lim_{n \rightarrow \infty} \text{ Pr }(|\bar X_n - \mu| < \epsilon) = 1.\end{array}$$

> 随机变量的 **样本均值** $$\bar X_n$$ `概率收敛`于随机样本所在群体的 **总体平均值**  $$\mu$$ .

---

# 方差与标准差

**标准差** 是 **方差Variance** 的平方根，方差可以表示为：
$$Var(X) = \sigma^2 = E[(X - E[X])^2] = \sum_i (x_i - E[X])^2p_i.$$

方差的表示式可以扩展为：

$$\begin{array}{l}
E[(X - E[X])^2] & = & E[(X - \mu)^2]   \\  
& = & E[X^2 + \mu^2 - 2 X\mu]   \\  
& = & E[X^2] -2E[X]\mu + E[\mu^2]   \\  
& = & E[X^2] - 2\mu^2 + \mu^2   \\  
& = & E[X^2] - \mu^2   \\  
& = & \sum_i x_i^2 p_i - (\sum_i x_i p_i)^2   \\  
& = & \sum_i x_i^2 p_i - \mu^2.
\end{array}$$

---

如果所有的随机变量具有相同的概率：


$$Var(X) = \sum_{i=1}^n{ { (x_i - \bar X)^2} \over n }.$$

---

方差的属性可以通过 **期望的四个公式** 以及 **一个方差公式** 推出：

$$\begin{array}{l}
E[X + c] = E[X] + c,   \\   E[cX] = c E[X],   \\   E[X +Y] = E[X]+E[Y],  \\  E[E[X] = E[X].
\end{array}$$

$$
\begin{array}{l}
Var(X) &=& E[(X - E[X])^2]   \\   & =& E[X^2 - 2X E[X] + E[X]^2],  \\  
& =& E[X^2] - 2 E[X] E[X] + E[X]^2,   \\  
& =& E[X^2] - E[X]^2.
\end{array}
$$

---

# 概率分布：第2部分
